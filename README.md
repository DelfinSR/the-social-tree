# üå≥ The Social Tree - El √Årbol Social üï∏Ô∏è

[![Version](https://img.shields.io/badge/version-1.0.0-green.svg)](https://github.com/antoniommff/the-social-tree/releases)
[![Python](https://img.shields.io/badge/python-3.12.X-blue.svg)](https://www.python.org/)
[![Jupyter](https://img.shields.io/badge/jupyter-notebook-orange.svg)](https://jupyter.org/)


## Content table - Tabla de contenido

- [About - Acerca de](#about)
- [Usage - Uso](#usage)
- [Documentation - Documentaci√≥n](#documentation)
- [Contact - Contacto](#contact)



<br></br>

## <a name="about"></a>About - Acerca de

[EN]
**In this project conducted in collaboration with [Antonio Mac√≠as](https://github.com/antoniommff), we have performed a study of *relational metrics* for a dataset in the form of a graph that can be used to train a relational machine learning model**.

Using the programming language *Python* and leveraging libraries such as *[scikit-learn](https://scikit-learn.org/stable/)*, we extracted relational features from a graph with over 20,000 *Facebook* pages to determine which group each belonged to. The groups the pages could belong to are: 'politicians', 'government organizations', 'TV shows', and 'companies'.

After training and evaluating several models with various combinations of metrics and hyperparameters, **we concluded that a classification tree algorithm (*CART*) is the most suitable for this machine learning task**. On the other hand, **using the [node2vec](https://snap.stanford.edu/node2vec/) library, we managed to train a classification algorithm using a *Knn* model with an accuracy of over 90%**, even greater than the previously mentioned.

In the following sections, we explain how to run the *Jupyter* notebooks with the code and summarize what you will find in the study document.

[ES]
**En este proyecto realizado en conjunto con [Antonio Mac√≠as](https://github.com/antoniommff) hemos realizado un estudio de m√©tricas relacionales para un conjunto de datos en forma de grafo que sirvan para entrenar a un modelo de aprendizaje autom√°tico relacional**. 

Usando el lenguaje de programaci√≥n *Python* y ayud√°ndonos de librer√≠as como *[scikit-learn](https://scikit-learn.org/stable/)*, hemos obtenido caracter√≠sticas relacionales de un grafo con m√°s de 20,000 p√°ginas de *Facebook* para averiguar a qu√© grupo pertenec√≠a cada una de ellas. Los grupos a los que pod√≠a pertenecer las p√°ginas eran los siguientes: politicos, organizaciones gubernamentales, programas de televisi√≥n y empresas. 

Tras entrenar y evaluar varios modelos con varias combinaciones de m√©trica e hiperpar√°metros, **hemos conclu√≠do que un algoritmo de √°rboles de clasificaci√≥n (*CART*) es el m√°s adecuado para esta tarea de aprendizaje autom√°tico**. Por otro lado, **usando la librer√≠a [node2vec](https://snap.stanford.edu/node2vec/), conseguimos entrenar un algoritmo de clasificaci√≥n usando un modelo *Knn* con una precisi√≥n de m√°s del 90%**, incluso mayor que la anteriormente mencionada. 

En los siguientes apartados explicamos c√≥mo ejecutar los cuadernos de *Jupyter* con el c√≥digo y resumimos qu√© podr√°s encontrar en documento del estudio realizado.



<br></br>

## <a name="usage"></a>Usage - Uso

### 0. Download necessary programmes and libraries - Descargar programas y librer√≠as necesarias:

[EN]
To start our project and experiment with the trained models, we recommend following these steps:
First, we recommend using the version of `Python 3.12.8` or higher, which is the one we have used for all notebooks. Also, you must install the latest version of `Jupyter notebook` to run the notebooks with the code, and `Conda`, which will be necessary to run *Jupyter* and some libraries such as *numpy*. Finally, the following libraries used throughout the code will have to be installed:

[ES]
Para poner en marcha nuestro proyecto y experimentar con los modelos entrenados recomendamos seguir los siguientes pasos:
Primero, recomendamos usar la versi√≥n de `Python 3.12.8` o superior, que es la que hemos usado para todos lo cuadernos. Tambi√©n, deber√°s instalar la √∫ltima versi√≥n de `Jupyter notebook` para ejecutar los cuadernos con el c√≥digo, y `Conda` que ser√° necesario para ejecutar tanto *Jupyter* como algunas librer√≠as como *numpy*. Por √∫ltimo, habr√° que tener instaladas las siguienes librer√≠as que se usan a lo largo de todo el c√≥digo:


- [Matplotlib](https://matplotlib.org/stable/install/index.html) (>= 3.9)
- [Networx](https://github.com/networkx/networkx) (>= 3.3)
- [Numpy](https://numpy.org/install/) (>= 2.0.0)
- [SciPy](https://scipy.org/install/) (>= 1.13.X)
- [Scikit-learn](https://scikit-learn.org/stable/install.html) (>=1.5)
- [Pandas](https://pandas.pydata.org/pandas-docs/stable/getting_started/install.html) (>=2.2.X)
- [Node2Vec](https://github.com/aditya-grover/node2vec) (latest)

### 1. Clone the repository - Clonar el repositorio:

[EN]
First, you must clone our repository or download the folders and place them in the desired location.

[ES]
Primero, deber√°s clonar nuestro repositorio o descargar las carpetas y colocarlas en la ubicaci√≥n deseada.

### 2. Download the data - Descargar los datos:

[EN]
Next, you will have to download the *Facebook* data used to train the models. You must download them and enter them in the folder called `facebook_large` or name the folder of the data you download with the same name. In any case, the folder with the data must be at the same directory level as the `cadernos` folder.

[ES]
Seguidamente, deber√°s descargar los datos de *Facebook* utilizados para entrenar a los modelos. Debes descargarlos e introducirlos en la carpeta llamada `facebook_large` o nombrar la carpeta de los datos que descargues con ese mismo nombre. En cualquier caso la carpeta con los datos debe estar en el mismo nivel de directorio que la carpeta `cuadernos`.

**Link - Enlace: https://snap.stanford.edu/data/facebook-large-page-page-network.html**

### 3. Run the notebooks! - ¬°Ejecutar los cuadernos!

[EN]
Now you will only have to run the *Jupyter* notebooks in order and explore the models. You can find them all in the `cuadernos` folder. In the `grafos` folder you can find the representations of the graphs already generated after the execution of the first notebooks. These take a long time to execute, that's why we already provide the representations obtained after their execution.

[ES]
Ahora solo tendr√°s que ejecutar los cuadernos de *Jupyter* en orden y exploarar los modelos. Podr√°s encontrarlos todos en la carpeta `cuadernos`. En la carpeta `grafos` podr√°s encontrar las representaciones de los grafos ya generadas tras la ejecuci√≥n de los primeros cuadernos. Estos tardan bastante en ejecutarse, por eso aportamos directamente las representaciones obtenidas tras su ejecuci√≥n.



<br></br>

## <a name="documentation"></a>Documentation - Documentaci√≥n

[EN]
You can find a complete study in the file [El-arbol-social.pdf](https://github.com/DelfinSR/the-social-tree/blob/main/El-arbol-social.pdf). There, we delve into the mathematical and more technical details of the entire code, and the results obtained after the training of the models are discussed in further detail.

[ES]
Podr√°s encontrar un estudio completo en el archivo [El-arbol-social.pdf](https://github.com/DelfinSR/the-social-tree/blob/main/El-arbol-social.pdf). Aqu√≠, profundizamos en los detalles matem√°ticos y m√°s tecnicos de todo el c√≥digo y se comentan en detalle los resultados obtenidos tras el entrenamiento de los modelos.

<br></br>

## <a name="contact"></a>Contact - Contacto

**Delf√≠n Santana Rubio: https://github.com/DelfinSR**
<br></br>
**Antonio Mac√≠as Ferrera: https://github.com/antoniommff ; https://bento.me/antoniommff**

<br></br>

